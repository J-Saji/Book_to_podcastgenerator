{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --clear-output"
      ],
      "metadata": {
        "id": "gxkb3CFrR7h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWmEs-jKfl97"
      },
      "outputs": [],
      "source": [
        "%pip install pypdf\n",
        "%pip install transformers\n",
        "%pip install pdfminer.six\n",
        "%pip install pdf2image\n",
        "%pip install pytesseract\n",
        "%pip install poppler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "sHYvmi1GgXq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install huggingface_hub[hf_xet]"
      ],
      "metadata": {
        "id": "8juWxAirf0Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "def is_pdf_text_based(pdf_path):\n",
        "    text = extract_text(pdf_path, maxpages=1)\n",
        "    return bool(text.strip())\n",
        "\n",
        "def extract_text_from_pdf(pdf_path, output_path):\n",
        "    if is_pdf_text_based(pdf_path):\n",
        "        print(\"PDF has selectable text. Using pdfminer.\")\n",
        "        text = extract_text(pdf_path)\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(text)\n",
        "    else:\n",
        "        print(\"PDF appears to be scanned. Using OCR.\")\n",
        "        images = convert_from_path(pdf_path)\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for i, img in enumerate(images):\n",
        "                text = pytesseract.image_to_string(img)\n",
        "                f.write(f\"\\n--- Page {i+1} ---\\n{text}\")\n",
        "\n",
        "# Example\n",
        "extract_text_from_pdf('/content/Ikigai.pdf', \"final_output.txt\")"
      ],
      "metadata": {
        "id": "iO0Wr9gLf2WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_book_text(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "    return text\n",
        "\n",
        "def chunk_text(text, max_words=800):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), max_words):\n",
        "        chunk = \" \".join(words[i:i + max_words])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "# Load and chunk the text\n",
        "book_text = load_book_text(\"final_output.txt\")\n",
        "text_chunks = chunk_text(book_text, max_words=1000)\n",
        "\n",
        "print(f\" Total chunks created: {len(text_chunks)}\")\n",
        "print(f\"\\n First 300 characters of chunk 1:\\n{text_chunks[0][:300]}\")"
      ],
      "metadata": {
        "id": "TGwna4Jegc61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  import re\n",
        "\n",
        "  def load_clean_text(file_path):\n",
        "      with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "          text = f.read()\n",
        "      # Remove OCR page markers like \"--- Page 1 ---\"\n",
        "      cleaned_text = re.sub(r\"\\n*--- Page \\d+ ---\\n*\", \"\\n\", text)\n",
        "      return cleaned_text\n",
        "\n",
        "  # Load and clean\n",
        "  cleaned_book_text = load_clean_text(\"final_output.txt\")\n",
        "\n",
        "  # Then chunk\n",
        "  text_chunks = chunk_text(cleaned_book_text, max_words=1000)\n",
        "\n",
        "  print(f\"‚úÖ Total cleaned chunks: {len(text_chunks)}\")\n",
        "  print(f\"\\nüîπ First 300 characters of cleaned chunk 1:\\n{text_chunks[0][:300]}\")"
      ],
      "metadata": {
        "id": "9eINnXeCghta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "# Summarization function without pipeline (manual for more control)\n",
        "def safe_summarize(text, max_input_tokens=1024, max_output_tokens=600, min_output_tokens=300):\n",
        "    # Tokenize and move to GPU\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens).to(device)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_output_tokens,\n",
        "        min_length=min_output_tokens,\n",
        "        do_sample=False,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Summarize all text chunks\n",
        "summaries = []\n",
        "for i, chunk in enumerate(text_chunks):\n",
        "    print(f\"‚è≥ Summarizing chunk {i+1}/{len(text_chunks)}...\")\n",
        "    try:\n",
        "        summary = safe_summarize(chunk)\n",
        "        summaries.append(summary)\n",
        "    except Exception as e:\n",
        "        print(f\" Chunk {i+1} failed: {e}\")\n",
        "        summaries.append(\"\")\n",
        "\n",
        "# Save summaries\n",
        "with open(\"summarized_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, summary in enumerate(summaries, start=1):\n",
        "        f.write(f\"Summary {i}:\\n{summary}\\n\\n\")\n",
        "\n",
        "print(\" All done! Summaries saved to 'summarized_output1.txt'.\")\n"
      ],
      "metadata": {
        "id": "vA7UkpLSgmpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "yXbzG78flSny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "D9NCnrjhlWgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama serve\n",
        "!ollama pull mistral\n",
        "!ollama generate \"Hello, world!\""
      ],
      "metadata": {
        "id": "IU3_sBEYhpT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def prompt_ollama_for_dialogue(summary_text):\n",
        "    prompt = f\"\"\"Turn the following book summary into a podcast-style dialogue between two co-hosts, Host 1 and Host 2.\n",
        "Keep the tone conversational, engaging, and informative. Host 1 can lead with a topic, and Host 2 can ask questions,\n",
        "react, or add insights. Avoid reading like a summary ‚Äî make it sound like a natural discussion.\n",
        "\n",
        "---\n",
        "\"{summary_text}\"\n",
        "\"\"\"\n",
        "\n",
        "    response = requests.post(\n",
        "        'http://localhost:11434/api/generate',\n",
        "        json={\n",
        "            \"model\": \"mistral\",\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()['response'].strip()\n",
        "    else:\n",
        "        print(\"Error from Ollama:\", response.text)\n",
        "        return \"\"\n",
        "\n",
        "def generate_podcast_dialogue(input_file='summarized_output.txt', output_file='podcast_dialogue_output.txt'):\n",
        "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
        "        paragraphs = infile.read().split(\"\\n\\n\")  # split multiple summaries if any\n",
        "\n",
        "    all_dialogues = []\n",
        "\n",
        "    for i, para in enumerate(paragraphs):\n",
        "        if para.strip():\n",
        "            print(f\"Generating dialogue for section {i + 1}...\")\n",
        "            dialogue = prompt_ollama_for_dialogue(para.strip())\n",
        "            all_dialogues.append(f\"--- Dialogue {i + 1} ---\\n{dialogue}\\n\")\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(\"\\n\".join(all_dialogues))\n",
        "\n",
        "    print(f\"\\n Podcast dialogues saved to {output_file}\")\n",
        "\n",
        "# Run the generator\n",
        "generate_podcast_dialogue()"
      ],
      "metadata": {
        "id": "BijPmehNhQPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install edge-tts pydub\n"
      ],
      "metadata": {
        "id": "Z4hOI564sGnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import asyncio\n",
        "import edge_tts\n",
        "import os\n",
        "\n",
        "# Read uploaded dialogue\n",
        "dialogue_lines = []\n",
        "with open(\"/content/podcast_dialogue_output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        if line.startswith(\"Host 1:\"):\n",
        "            text = line.replace(\"Host 1:\", \"\").strip()\n",
        "            dialogue_lines.append((\"en-US-GuyNeural\", text))  # Voice A\n",
        "        elif line.startswith(\"Host 2:\"):\n",
        "            text = line.replace(\"Host 2:\", \"\").strip()\n",
        "            dialogue_lines.append((\"en-US-JennyNeural\", text))  # Voice B\n",
        "\n",
        "os.makedirs(\"edge_tts_audio\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "FXiwyULvsKk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue_lines = []\n",
        "with open(\"/content/podcast_dialogue_output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line or \":\" not in line:\n",
        "            continue  # skip empty/bad lines\n",
        "        if line.startswith(\"Host 1:\"):\n",
        "            text = line.replace(\"Host 1:\", \"\").strip()\n",
        "            if text:\n",
        "                dialogue_lines.append((\"en-US-GuyNeural\", text))\n",
        "        elif line.startswith(\"Host 2:\"):\n",
        "            text = line.replace(\"Host 2:\", \"\").strip()\n",
        "            if text:\n",
        "                dialogue_lines.append((\"en-US-JennyNeural\", text))\n"
      ],
      "metadata": {
        "id": "fHfR_G2Vt6XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loaded {len(dialogue_lines)} lines for TTS.\")"
      ],
      "metadata": {
        "id": "wgtqXetot8Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def generate_tts():\n",
        "    tasks = []\n",
        "    for i, (voice, text) in enumerate(dialogue_lines):\n",
        "        filename = f\"edge_tts_audio/line_{i+1:03d}.mp3\"\n",
        "        communicate = edge_tts.Communicate(text=text, voice=voice)\n",
        "        task = communicate.save(filename)\n",
        "        tasks.append(task)\n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "await generate_tts()\n"
      ],
      "metadata": {
        "id": "ITxErrOcs3C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine into single audio\n",
        "final_audio = AudioSegment.empty()\n",
        "for i in range(len(dialogue_lines)):\n",
        "    clip = AudioSegment.from_file(f\"edge_tts_audio/line_{i+1:03d}.mp3\")\n",
        "    final_audio += clip + AudioSegment.silent(duration=300)\n",
        "\n",
        "final_audio.export(\"final_podcast_edge_tts.mp3\", format=\"mp3\")\n",
        "print(\" Final podcast saved as final_podcast_edge_tts.mp3\")"
      ],
      "metadata": {
        "id": "g7RarlTGs4vE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}